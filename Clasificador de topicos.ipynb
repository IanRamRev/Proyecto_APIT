{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import pandas\n",
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los topicos se encuentran juntos en el dataframe, esta función los separa de acuerdo al tema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separaTopico(topico, df): #Separa todos los encabezados de acuerdo a su tópico\n",
    "    listTopic = []\n",
    "    dataArr = numpy.asarray(df)\n",
    "    for i in range(len(dataArr)):\n",
    "        if(dataArr[i][1] == topico):\n",
    "            listTopic.append(dataArr[i][0])\n",
    "    return listTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cuando se tienen las palabras unicas de cada tópico, se eliminan caracteres especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiaTexto(text):\n",
    "    \"List all the word tokens in a text.\"\n",
    "    return re.findall('[a-zA-Z0-9\\-]{4,254}', text.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cada encabezado corresponde a un documento, esta función separa cada palabra para agregarlas a un solo array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PalabrasTopico(listTopico): #Devuelve todas las palabras que aparecen en los titulares de las noticias \n",
    "    listHeadLines = []\n",
    "    for i in range(len(listTopico)):\n",
    "        #aux = nltk.word_tokenize(arrayTopico[i])\n",
    "        aux = limpiaTexto(listTopico[i])\n",
    "        for j in range(len(aux)):\n",
    "            aux2 = aux[j]\n",
    "            listHeadLines.append(aux2)\n",
    "            \n",
    "    return numpy.asarray(listHeadLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Probabilidad(palabrasTopico, palabrasUnicasTopico): #Devuelve un array con la ocurrencias de cada única del tópico\n",
    "    probabilidad = numpy.zeros(len(palabrasUnicasTopico))\n",
    "    for i in range(len(palabrasUnicasTopico)):\n",
    "        probabilidad[i] = numpy.sum(palabrasTopico == palabrasUnicasTopico[i])\n",
    "        probabilidad[i] = probabilidad[i] /len(palabrasTopico)\n",
    "        \n",
    "    return probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probTopico(dataTrain, arrayTopic):\n",
    "    return len(arrayTopic)/len(dataTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Abrimos el dataset con pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titular</th>\n",
       "      <th>Tópico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Que política o economía conduzcan respuesta al...</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oaxaca habilita red de hospitales para covid-19</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Surgen más brotes de covid-19 en asilo y empre...</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suman cuatro mil 477 muertos y 42 mil 595 cont...</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Revelan que más de mil 400 mujeres han solicit...</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>En los Parapanamericanos, México suma ya 42 or...</td>\n",
       "      <td>deportes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>El futbolista Jonathan Fabbro es condenado a 1...</td>\n",
       "      <td>deportes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>México cosecha 50 medallas en el paraatletismo...</td>\n",
       "      <td>deportes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>Debut y gol de Edson Álvarez que da pase al Aj...</td>\n",
       "      <td>deportes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>Rosa Guerrero, oro en lanzamiento de disco en ...</td>\n",
       "      <td>deportes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Titular    Tópico\n",
       "0     Que política o economía conduzcan respuesta al...     covid\n",
       "1       Oaxaca habilita red de hospitales para covid-19     covid\n",
       "2     Surgen más brotes de covid-19 en asilo y empre...     covid\n",
       "3     Suman cuatro mil 477 muertos y 42 mil 595 cont...     covid\n",
       "4     Revelan que más de mil 400 mujeres han solicit...     covid\n",
       "...                                                 ...       ...\n",
       "1195  En los Parapanamericanos, México suma ya 42 or...  deportes\n",
       "1196  El futbolista Jonathan Fabbro es condenado a 1...  deportes\n",
       "1197  México cosecha 50 medallas en el paraatletismo...  deportes\n",
       "1198  Debut y gol de Edson Álvarez que da pase al Aj...  deportes\n",
       "1199  Rosa Guerrero, oro en lanzamiento de disco en ...  deportes\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres = ['Titular', 'Tópico']\n",
    "dataTrain = pandas.read_csv('titulares.csv', names=nombres)\n",
    "dataTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separamos del dataset por tópicos y a cada encabezado lo separamos por palabra de los documentos eliminando caracteres especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3823,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabrasCovid = PalabrasTopico(separaTopico('covid', dataTrain))\n",
    "AlfabetoCovid = numpy.unique(palabrasCovid)\n",
    "#print(len(palabrasCovid))\n",
    "#print(len(AlfabetoCovid))\n",
    "\n",
    "\n",
    "palabrasTecn = PalabrasTopico(separaTopico('tecnologia', dataTrain))\n",
    "AlfabetoTecn = numpy.unique(palabrasTecn)\n",
    "\n",
    "palabrasDep = PalabrasTopico(separaTopico('deportes', dataTrain))\n",
    "AlfabetoDep = numpy.unique(palabrasDep)\n",
    "\n",
    "Alfabeto = numpy.concatenate((AlfabetoCovid, AlfabetoTecn, AlfabetoDep))\n",
    "Alfabeto.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtenemos las probabilidades a priori, haciendo cada una de estas equiprobabloe $ P(C) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCovid =  0.3333333333333333 PTecn =  0.3333333333333333 PDep =  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "PCovid = 1/3\n",
    "PTecn = 1/3\n",
    "PDep = 1/3\n",
    "print(\"PCovid = \", PCovid, \"PTecn = \", PTecn, \"PDep = \", PDep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtenemos la frecuencia de palabras de cada tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00035075 0.00035075 0.0038583  ... 0.00035075 0.00070151 0.00035075]\n"
     ]
    }
   ],
   "source": [
    "ProbCovid = Probabilidad(palabrasCovid, AlfabetoCovid)\n",
    "ProbTecn = Probabilidad(palabrasTecn, AlfabetoTecn)\n",
    "ProbDep = Probabilidad(palabrasDep, AlfabetoDep)\n",
    "print(ProbDep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculamos la probabilidad de cada clase, dado una cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pword(word, alfabeto):\n",
    "    P = numpy.sum(alfabeto == word)\n",
    "    P = P/len(alfabeto)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(Covid) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"pandemia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pmax (cadena):\n",
    "    Proba = numpy.zeros(3)\n",
    "    \n",
    "    for i in range(len(AlfabetoCovid)):\n",
    "        if(AlfabetoCovid[i] == texto):\n",
    "            Proba[0] = PCovid * ProbCovid[i]\n",
    "            \n",
    "    for i in range(len(AlfabetoTecn)):\n",
    "        if(AlfabetoTecn[i] == texto):\n",
    "            Proba[1] = PTecn * ProbTecn[i]\n",
    "            \n",
    "    for i in range(len(AlfabetoDep)):\n",
    "        if(AlfabetoDep[i] == texto):\n",
    "            Proba[2] = PTecn * ProbDep[i]\n",
    "            \n",
    "    return Proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00426829 0.         0.00035075]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004268292682926829"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Pmax(texto)\n",
    "print(result)\n",
    "masRes = max(result)\n",
    "masRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
